{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c3fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ashankar/DataMiningRBMs/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import sys, os\n",
    "sys.path.append('../Netket/')\n",
    "import netket as nk\n",
    "from jax import numpy as jnp\n",
    "import itertools\n",
    "from scipy.special import comb\n",
    "from jax import jit, vmap\n",
    "import jax\n",
    "import matplotlib.pyplot as plt \n",
    "from cluster_expansion import fwht_coeffs_in_cluster_col_order, prepare_fwht_meta_cached, compress_and_reconstruct_cached, _get_topk_indices_jit\n",
    "import analysis\n",
    "from analysis import std_phase, ipr, pca_entropy, renyi_entropy, mean_amplitude, uniform_state_overlap, infidelity\n",
    "import pandas as pd\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129bba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n"
     ]
    }
   ],
   "source": [
    "hypotheses = {\n",
    "    \"std_phase\" : std_phase,\n",
    "    \"IPR\" : ipr,\n",
    "    \"SPCA\" : pca_entropy,\n",
    "    \"Renyi_2\" : renyi_entropy,\n",
    "    \"uniform_state_overlap\" : uniform_state_overlap,\n",
    "    \"mean_amplitude\" : mean_amplitude,\n",
    "}\n",
    "\n",
    "data_root = '..'\n",
    "\n",
    "h5_files_opt = [os.path.join(f\"{data_root}/data/data_optimal_basis_rbm\", f) for f in os.listdir(f'{data_root}/data/data_optimal_basis_rbm') if f.endswith('.h5')]\n",
    "df_opt = analysis.load_outputs_to_dataframe(h5_files_opt, load_eigenstates=False)\n",
    "df_opt = analysis.attach_hypotheses_fields(df_opt, hypotheses)\n",
    "df_opt[\"idx\"] = df_opt[\"file\"].apply(lambda x: int(os.path.basename(x).split('_')[2]))\n",
    "print(len(df_opt))\n",
    "\n",
    "# h5_files_raw = [os.path.join(f\"{data_root}/data/data_unrotated_basis_rbm\", f) for f in os.listdir(f'{data_root}/data/data_unrotated_basis_rbm') if f.endswith('.h5')]\n",
    "# df_raw = analysis.load_outputs_to_dataframe(h5_files_raw, load_eigenstates=False)\n",
    "# df_raw = analysis.attach_hypotheses_fields(df_raw, hypotheses)\n",
    "# df_raw[\"idx\"] = df_raw[\"file\"].apply(lambda x: int(os.path.basename(x).split('_')[2]))\n",
    "# print(len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c5be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "iteration  1\n",
      "iteration  1\n",
      "iteration  2\n",
      "iteration  2\n",
      "iteration  3\n",
      "iteration  3\n",
      "iteration  4\n",
      "iteration  4\n",
      "iteration  5\n",
      "iteration  5\n",
      "iteration  6\n",
      "iteration  6\n",
      "iteration  7\n",
      "iteration  7\n",
      "iteration  8\n",
      "iteration  8\n",
      "iteration  9\n",
      "iteration  9\n",
      "iteration  10\n",
      "iteration  10\n",
      "iteration  11\n",
      "iteration  11\n",
      "iteration  12\n",
      "iteration  12\n",
      "iteration  13\n",
      "iteration  13\n",
      "iteration  14\n",
      "iteration  14\n",
      "iteration  15\n",
      "iteration  15\n",
      "iteration  16\n",
      "iteration  16\n",
      "iteration  17\n",
      "iteration  17\n",
      "iteration  18\n",
      "iteration  18\n",
      "iteration  19\n",
      "iteration  19\n",
      "iteration  20\n",
      "iteration  20\n",
      "iteration  21\n",
      "iteration  21\n",
      "iteration  22\n",
      "iteration  22\n",
      "iteration  23\n",
      "iteration  23\n",
      "iteration  24\n",
      "iteration  24\n",
      "iteration  25\n",
      "iteration  25\n",
      "iteration  26\n",
      "iteration  26\n",
      "iteration  27\n",
      "iteration  27\n",
      "iteration  28\n",
      "iteration  28\n",
      "iteration  29\n",
      "iteration  29\n",
      "iteration  30\n",
      "iteration  30\n",
      "iteration  31\n",
      "iteration  31\n",
      "iteration  32\n",
      "iteration  32\n",
      "iteration  33\n",
      "iteration  33\n",
      "iteration  34\n",
      "iteration  34\n",
      "iteration  35\n",
      "iteration  35\n",
      "iteration  36\n",
      "iteration  36\n",
      "iteration  37\n",
      "iteration  37\n",
      "iteration  38\n",
      "iteration  38\n",
      "iteration  39\n",
      "iteration  39\n",
      "iteration  40\n",
      "iteration  40\n",
      "iteration  41\n",
      "iteration  41\n",
      "iteration  42\n",
      "iteration  42\n",
      "iteration  43\n",
      "iteration  43\n",
      "iteration  44\n",
      "iteration  44\n",
      "iteration  45\n",
      "iteration  45\n",
      "iteration  46\n",
      "iteration  46\n",
      "iteration  47\n",
      "iteration  47\n",
      "iteration  48\n",
      "iteration  48\n",
      "iteration  49\n",
      "iteration  49\n",
      "iteration  50\n",
      "iteration  50\n",
      "iteration  51\n",
      "iteration  51\n",
      "iteration  52\n",
      "iteration  52\n",
      "iteration  53\n",
      "iteration  53\n",
      "iteration  54\n",
      "iteration  54\n",
      "iteration  55\n",
      "iteration  55\n",
      "iteration  56\n",
      "iteration  56\n",
      "iteration  57\n",
      "iteration  57\n",
      "iteration  58\n",
      "iteration  58\n",
      "iteration  59\n",
      "iteration  59\n",
      "iteration  60\n",
      "iteration  60\n",
      "iteration  61\n",
      "iteration  61\n",
      "iteration  62\n",
      "iteration  62\n",
      "iteration  63\n",
      "iteration  63\n",
      "iteration  64\n",
      "iteration  64\n",
      "iteration  65\n",
      "iteration  65\n",
      "iteration  66\n",
      "iteration  66\n",
      "iteration  67\n",
      "iteration  67\n",
      "iteration  68\n",
      "iteration  68\n",
      "iteration  69\n",
      "iteration  69\n",
      "iteration  70\n",
      "iteration  70\n",
      "iteration  71\n",
      "iteration  71\n",
      "iteration  72\n",
      "iteration  72\n",
      "iteration  73\n",
      "iteration  73\n",
      "iteration  74\n",
      "iteration  74\n",
      "iteration  75\n",
      "iteration  75\n",
      "iteration  76\n",
      "iteration  76\n",
      "iteration  77\n",
      "iteration  77\n",
      "iteration  78\n",
      "iteration  78\n",
      "iteration  79\n",
      "iteration  79\n",
      "iteration  80\n",
      "iteration  80\n",
      "iteration  81\n",
      "iteration  81\n",
      "iteration  82\n",
      "iteration  82\n",
      "iteration  83\n",
      "iteration  83\n",
      "iteration  84\n",
      "iteration  84\n",
      "iteration  85\n",
      "iteration  85\n",
      "iteration  86\n",
      "iteration  86\n",
      "iteration  87\n",
      "iteration  87\n",
      "iteration  88\n",
      "iteration  88\n",
      "iteration  89\n",
      "iteration  89\n",
      "iteration  90\n",
      "iteration  90\n",
      "iteration  91\n",
      "iteration  91\n",
      "iteration  92\n",
      "iteration  92\n",
      "iteration  93\n",
      "iteration  93\n",
      "iteration  94\n",
      "iteration  94\n",
      "iteration  95\n",
      "iteration  95\n",
      "iteration  96\n",
      "iteration  96\n",
      "iteration  97\n",
      "iteration  97\n",
      "iteration  98\n",
      "iteration  98\n",
      "iteration  99\n",
      "iteration  99\n",
      "iteration  100\n",
      "iteration  100\n",
      "iteration  101\n",
      "iteration  101\n",
      "iteration  102\n",
      "iteration  102\n",
      "iteration  103\n",
      "iteration  103\n",
      "iteration  104\n",
      "iteration  104\n",
      "iteration  105\n",
      "iteration  105\n",
      "iteration  106\n",
      "iteration  106\n",
      "iteration  107\n",
      "iteration  107\n",
      "iteration  108\n",
      "iteration  108\n",
      "iteration  109\n",
      "iteration  109\n",
      "iteration  110\n",
      "iteration  110\n",
      "iteration  111\n",
      "iteration  111\n",
      "iteration  112\n",
      "iteration  112\n",
      "iteration  113\n",
      "iteration  113\n",
      "iteration  114\n",
      "iteration  114\n",
      "iteration  115\n",
      "iteration  115\n",
      "iteration  116\n",
      "iteration  116\n",
      "iteration  117\n",
      "iteration  117\n",
      "iteration  118\n",
      "iteration  118\n",
      "iteration  119\n",
      "iteration  119\n",
      "iteration  120\n",
      "iteration  120\n",
      "iteration  121\n",
      "iteration  121\n",
      "iteration  122\n",
      "iteration  122\n",
      "iteration  123\n",
      "iteration  123\n",
      "iteration  124\n",
      "iteration  124\n",
      "iteration  125\n",
      "iteration  125\n",
      "iteration  126\n",
      "iteration  126\n",
      "iteration  127\n",
      "iteration  127\n",
      "iteration  128\n",
      "iteration  128\n",
      "iteration  129\n",
      "iteration  129\n",
      "iteration  130\n",
      "iteration  130\n",
      "iteration  131\n",
      "iteration  131\n",
      "iteration  132\n",
      "iteration  132\n",
      "iteration  133\n",
      "iteration  133\n",
      "iteration  134\n",
      "iteration  134\n",
      "iteration  135\n",
      "iteration  135\n",
      "iteration  136\n",
      "iteration  136\n",
      "iteration  137\n",
      "iteration  137\n",
      "iteration  138\n",
      "iteration  138\n",
      "iteration  139\n",
      "iteration  139\n",
      "iteration  140\n",
      "iteration  140\n",
      "iteration  141\n",
      "iteration  141\n",
      "iteration  142\n",
      "iteration  142\n",
      "iteration  143\n",
      "iteration  143\n",
      "iteration  144\n",
      "iteration  144\n",
      "iteration  145\n",
      "iteration  145\n",
      "iteration  146\n",
      "iteration  146\n",
      "iteration  147\n",
      "iteration  147\n",
      "iteration  148\n",
      "iteration  148\n",
      "iteration  149\n",
      "iteration  149\n",
      "iteration  150\n",
      "iteration  150\n",
      "iteration  151\n",
      "iteration  151\n",
      "iteration  152\n",
      "iteration  152\n",
      "iteration  153\n",
      "iteration  153\n",
      "iteration  154\n",
      "iteration  154\n",
      "iteration  155\n",
      "iteration  155\n",
      "iteration  156\n",
      "iteration  156\n",
      "iteration  157\n",
      "iteration  157\n",
      "iteration  158\n",
      "iteration  158\n",
      "iteration  159\n",
      "iteration  159\n",
      "iteration  160\n",
      "iteration  160\n",
      "iteration  161\n",
      "iteration  161\n",
      "iteration  162\n",
      "iteration  162\n",
      "iteration  163\n",
      "iteration  163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m cluster_coeffs_test_RBM = fwht_coeffs_in_cluster_col_order(np.log(psi_test_RBM), hilb_test)\n\u001b[32m     20\u001b[39m prepare_fwht_meta_cached(hilb_test)  \u001b[38;5;66;03m# fill cache (fast)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m infidels_exact_opt = [\u001b[43minfidelity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompress_and_reconstruct_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_coeffs_test_exact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompr_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhilb_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_test_exact\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m compr_idx \u001b[38;5;129;01min\u001b[39;00m compr_idx_list]\n\u001b[32m     24\u001b[39m infidels_RBM_opt = [infidelity(compress_and_reconstruct_cached(cluster_coeffs_test_RBM, compr_idx, hilb_test), psi_test_exact) \n\u001b[32m     25\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m compr_idx \u001b[38;5;129;01min\u001b[39;00m compr_idx_list]\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# convert arrays to lists for safe storage in HDF5\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/ashankar/DataMiningRBMs/ClusterExpansion/../Netket/analysis.py:243\u001b[39m, in \u001b[36minfidelity\u001b[39m\u001b[34m(psi, psi_0)\u001b[39m\n\u001b[32m    240\u001b[39m     prob = prob[prob > \u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Avoid log(0) and zero division\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1.0\u001b[39m / (\u001b[32m1.0\u001b[39m - alpha) * np.log(np.sum(prob**alpha))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfidelity\u001b[39m(psi, psi_0):\n\u001b[32m    244\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[33;03m    Compute the infidelity between two state vectors psi and psi_0.\u001b[39;00m\n\u001b[32m    246\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    252\u001b[39m \u001b[33;03m        float: The infidelity value (1 - |<psi_0|psi>|^2).\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    254\u001b[39m     psi = np.asarray(psi)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "n_sites_test = 16\n",
    "hilb_test = nk.hilbert.Spin(0.5, n_sites_test)\n",
    "compr_idx_list = sorted(np.array(list(set(np.logspace(1, 16, 100, base=2, dtype=int)))))  \n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "\n",
    "idx_list = df_opt['idx'].values\n",
    "for i, idx in enumerate(idx_list):\n",
    "    print('iteration ', i)\n",
    "    row = df_opt.loc[df_opt['idx'] == idx]\n",
    "    if row.empty:\n",
    "        raise KeyError(f\"idx {idx} not found in df_opt\")\n",
    "\n",
    "    psi_test_exact = np.array(row['psi_0'].iloc[0])\n",
    "    psi_test_RBM = np.array(row['psi'].iloc[0])\n",
    "\n",
    "    cluster_coeffs_test_exact = fwht_coeffs_in_cluster_col_order(np.log(psi_test_exact), hilb_test)\n",
    "    cluster_coeffs_test_RBM = fwht_coeffs_in_cluster_col_order(np.log(psi_test_RBM), hilb_test)\n",
    "\n",
    "    prepare_fwht_meta_cached(hilb_test)  # fill cache (fast)\n",
    "\n",
    "    infidels_exact_opt = [infidelity(compress_and_reconstruct_cached(cluster_coeffs_test_exact, compr_idx, hilb_test), psi_test_exact) \n",
    "            for compr_idx in compr_idx_list]\n",
    "    infidels_RBM_opt = [infidelity(compress_and_reconstruct_cached(cluster_coeffs_test_RBM, compr_idx, hilb_test), psi_test_exact) \n",
    "            for compr_idx in compr_idx_list]\n",
    "    \n",
    "    # convert arrays to lists for safe storage in HDF5\n",
    "    dict_row = {\n",
    "            'idx': int(idx), \n",
    "            'infidels_exact_opt' : infidels_exact_opt,\n",
    "            'infidels_RBM_opt' : infidels_RBM_opt, \n",
    "            'cluster_coeffs_exact': np.array(cluster_coeffs_test_exact).tolist(), \n",
    "            'cluster_coeffs_RBM': np.array(cluster_coeffs_test_RBM).tolist()\n",
    "        }\n",
    "\n",
    "    # append the row to df_out\n",
    "    df_out = pd.concat([df_out, pd.DataFrame([dict_row])], ignore_index=True)\n",
    "\n",
    "# After loop, save dataframe to HDF5\n",
    "out_path = 'cluster_coeffs.h5'\n",
    "# Use format='table' for appendable, but here we write once\n",
    "try:\n",
    "    df_out.to_hdf(out_path, key='df', mode='w')\n",
    "    print(f\"Saved df_out to {out_path} (rows={len(df_out)})\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to save to HDF5 (falling back to pickle):\", e)\n",
    "    df_out.to_pickle('cluster_coeffs.pkl')\n",
    "    print(\"Saved df_out to cluster_coeffs.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee96bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_raw\u001b[49m[\u001b[33m'\u001b[39m\u001b[33midx\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c87449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
