{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9d5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../Netket/')\n",
    "import netket as nk\n",
    "from jax import numpy as jnp\n",
    "import itertools\n",
    "from scipy.special import comb\n",
    "from jax import jit, vmap\n",
    "import jax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4984f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert = nk.hilbert.Spin(s=0.5, N=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee5ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],      dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hstates = hilbert.all_states()\n",
    "hilbert.states_to_numbers(hstates)\n",
    "# hstates[0], hilbert.states_to_numbers(hstates[0])\n",
    "# type(hilbert.states_to_numbers(hstates[0]))\n",
    "\n",
    "# type(jnp.max(np.array([2,3])))\n",
    "# print(len(hstates))\n",
    "# hilbert.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae28256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_parity(bitstring):\n",
    "    '''\n",
    "    bitstring is a cluster, ex s1s2, or s1s2s3s4 etc\n",
    "    type of bitstring: jnp.array, dtype=jnp.int8\n",
    "    returns +1 if even parity, -1 if odd parity\n",
    "    '''\n",
    "    par = jnp.prod(bitstring,axis=-1,dtype=jnp.int8) #Since these are spin states +1 and -1\n",
    "    return par \n",
    "\n",
    "def naive_cluster_expansion_mat(hilbert):\n",
    "    '''Compute cluster expansion coefficients up to a given maximum cluster size.\n",
    "    for now only works for spin-1/2 systems\n",
    "    '''\n",
    "    # n_sites = hilbert.n_sites\n",
    "    n_sites = hilbert.size\n",
    "    hstates = hilbert.all_states()\n",
    "    matsize = 2**n_sites\n",
    "    mat = jnp.ones((matsize, matsize),dtype=jnp.int8)\n",
    "    for state_idx, state in enumerate(hstates):\n",
    "        start_idx = 1 #First column is all ones, so start from second column\n",
    "        for cluster_size in jnp.arange(1, n_sites + 1):\n",
    "            clusters = jnp.array(list(itertools.combinations(state, cluster_size)))\n",
    "            rowvals = return_parity(clusters)\n",
    "            mat = mat.at[state_idx, start_idx: start_idx + int(comb(n_sites, cluster_size))].set(rowvals)\n",
    "            start_idx += int(comb(int(n_sites), cluster_size))\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "637a0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_cluster_expansion(hilbert):\n",
    "    '''Maximum performance cluster expansion for large systems (N=16).\n",
    "    Uses vmap for automatic vectorization and JIT compilation.\n",
    "    '''\n",
    "    n_sites = hilbert.size\n",
    "    hstates = hilbert.all_states()\n",
    "    matsize = 2**n_sites\n",
    "    \n",
    "    # Pre-compute all cluster indices outside JIT (Python operations)\n",
    "    cluster_indices_list = []\n",
    "    for cluster_size in range(1, n_sites + 1):\n",
    "        clusters = list(itertools.combinations(range(n_sites), cluster_size))\n",
    "        cluster_indices_list.append(jnp.array(clusters, dtype=jnp.int32))\n",
    "    \n",
    "    total_clusters = sum(len(c) for c in cluster_indices_list)\n",
    "    \n",
    "    # Vectorized parity computation\n",
    "    @jit\n",
    "    def compute_parities_vectorized(state, clusters):\n",
    "        \"\"\"Compute parities for a single state across all clusters of a given size\"\"\"\n",
    "        # Shape: (n_clusters, cluster_size)\n",
    "        state_values = state[clusters]\n",
    "        # Compute parity: product along cluster axis\n",
    "        return jnp.prod(state_values, axis=-1, dtype=jnp.int8)\n",
    "    \n",
    "    # vmap over all states for each cluster size\n",
    "    @jit\n",
    "    def compute_all_parities(hstates, clusters):\n",
    "        \"\"\"Vectorized over all states\"\"\"\n",
    "        return vmap(lambda state: compute_parities_vectorized(state, clusters))(hstates)\n",
    "    \n",
    "    # Build matrix: move Python loop outside JIT\n",
    "    columns = [jnp.ones((matsize, 1), dtype=jnp.int8)]\n",
    "    \n",
    "    for clusters in cluster_indices_list:\n",
    "        parities = compute_all_parities(hstates, clusters)\n",
    "        columns.append(parities)\n",
    "    \n",
    "    # Concatenate all columns\n",
    "    mat = jnp.concatenate(columns, axis=1)\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a7e65b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1,  1,  1,  1],\n",
       "       [ 1,  1, -1, -1],\n",
       "       [ 1, -1,  1, -1],\n",
       "       [ 1, -1, -1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_cluster_expansion_mat(nk.hilbert.Spin(s=0.5, N=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b49dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_cluster_expansion_extreme(hilbert):\n",
    "    '''EXTREME optimization for N=16: trades memory for speed.\n",
    "    Uses batching and full vmap + JIT + GPU if available.\n",
    "    '''\n",
    "    n_sites = hilbert.size\n",
    "    hstates = hilbert.all_states()\n",
    "    matsize = 2**n_sites\n",
    "    \n",
    "    # Pre-compute all cluster indices\n",
    "    all_clusters = []\n",
    "    for cluster_size in range(1, n_sites + 1):\n",
    "        clusters = list(itertools.combinations(range(n_sites), cluster_size))\n",
    "        all_clusters.extend(clusters)\n",
    "    \n",
    "    all_clusters = jnp.array(all_clusters, dtype=jnp.int32)\n",
    "    total_clusters = len(all_clusters)\n",
    "    \n",
    "    @jit\n",
    "    def compute_all_parities_extreme(hstates, all_clusters):\n",
    "        \"\"\"\n",
    "        Compute all cluster parities at once.\n",
    "        Uses full vectorization: vmap over states, then vmap over clusters.\n",
    "        \"\"\"\n",
    "        def compute_single_parity(state, clusters):\n",
    "            \"\"\"Compute parity for a single state and cluster\"\"\"\n",
    "            return jnp.prod(state[clusters], dtype=jnp.int8)\n",
    "        \n",
    "        # vmap over clusters (for each state)\n",
    "        def parities_for_state(state):\n",
    "            return vmap(lambda cluster: compute_single_parity(state, cluster))(all_clusters)\n",
    "        \n",
    "        # vmap over states\n",
    "        return vmap(parities_for_state)(hstates)\n",
    "    \n",
    "    # Build final matrix\n",
    "    parities = compute_all_parities_extreme(hstates, all_clusters)\n",
    "    \n",
    "    # Prepend identity column\n",
    "    identity_col = jnp.ones((matsize, 1), dtype=jnp.int8)\n",
    "    mat = jnp.concatenate([identity_col, parities], axis=1)\n",
    "    \n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bec28cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 1,  1,  1, ..., -1, -1, -1],\n",
       "       [ 1,  1,  1, ..., -1, -1, -1],\n",
       "       ...,\n",
       "       [ 1, -1, -1, ...,  1,  1, -1],\n",
       "       [ 1, -1, -1, ...,  1,  1, -1],\n",
       "       [ 1, -1, -1, ..., -1, -1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_cluster_expansion(nk.hilbert.Spin(s=0.5, N=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0dbb74",
   "metadata": {},
   "source": [
    "### Tests for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68e37b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_naive = naive_cluster_expansion_mat(nk.hilbert.Spin(s=0.5, N=4))\n",
    "result_optim = optim_cluster_expansion(nk.hilbert.Spin(s=0.5, N=4))\n",
    "jnp.allclose(result_naive, result_optim)  # Should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64009a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_cluster_expansion(n_sites=16):\n",
    "    \"\"\"Benchmark all three implementations\"\"\"\n",
    "    hilbert = nk.hilbert.Spin(s=0.5, N=n_sites)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmarking N={n_sites} (matrix size: {2**n_sites} x ~{sum(comb(n_sites, k) for k in range(1, n_sites+1)) + 1})\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Warmup\n",
    "    try:\n",
    "        optim_cluster_expansion_extreme(nk.hilbert.Spin(s=0.5, N=4))\n",
    "        print(\"✓ JAX/GPU warmup complete\")\n",
    "    except:\n",
    "        print(\"⚠ GPU not available, using CPU\")\n",
    "    \n",
    "    # Test 1: Optimized with vmap\n",
    "    print(\"\\n[1] optim_cluster_expansion (vmap + JIT):\")\n",
    "    start = time.time()\n",
    "    result_vmap = optim_cluster_expansion(hilbert)\n",
    "    elapsed_vmap = time.time() - start\n",
    "    print(f\"    Time: {elapsed_vmap:.3f}s\")\n",
    "    print(f\"    Output shape: {result_vmap.shape}\")\n",
    "    \n",
    "    # Test 2: Extreme optimization\n",
    "    print(\"\\n[2] optim_cluster_expansion_extreme (full vmap + JIT):\")\n",
    "    start = time.time()\n",
    "    result_extreme = optim_cluster_expansion_extreme(hilbert)\n",
    "    elapsed_extreme = time.time() - start\n",
    "    print(f\"    Time: {elapsed_extreme:.3f}s\")\n",
    "    print(f\"    Output shape: {result_extreme.shape}\")\n",
    "    \n",
    "    # Verify correctness\n",
    "    print(f\"\\n✓ Results match: {jnp.allclose(result_vmap, result_extreme)}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Speedup: {elapsed_vmap/elapsed_extreme:.2f}x\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return result_extreme\n",
    "\n",
    "# Run benchmark for N=16\n",
    "mat_n16 = benchmark_cluster_expansion(n_sites=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
